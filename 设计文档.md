`node_type` 表示神经网络的节点数据类型。

# class Layer

## 成员变量

- `output_size:int`

  表示当前层节点的个数

- `input_size:int`
  
  表示前一层的节点个数

- `value:node_type[]`

  表示每个节点的激活值

- `integeration:node_type[]`

  表示每个节点的整合函数

- `biases:node_type[]`

  偏置

- `weights:node_type[][]`

  权重（到这一层）

- `ddelta:node_type[]`

  中间参数

- `activation:IFunction`

  激活函数接口（使用预设）



## 成员函数

- `Layer(int size, const Layer * pre, IFunction activation=sigmoid)`

  构造函数，用于创建层，size表示这个层的节点数量，activation表示这一层的激活函数，activation默认为sigmoid。

- `~Layer()`

  析构函数，释放数组资源。

- `void set_input(node_type array[])`

  将array中的元素依次复制为该层的输入。

- `void read_output()const`

  将当前层的结果输出。
  
- `const nodetype* get_val()`
  
  获取激活值
- `IFunction& get_IFunction()`
  
  获取激活函数
- ` void set_ddelta(node_type *delta) `

  用于输出层的ddelta导入
- `void save_data(string)`
  
  保存weight,bias,delta数据
- `void load_data(string)`
  
  读取保存的数据
  
- `void forward_propagation(bool use_activation = true)`

  前向传播，依据前一层的激活值计算本层的激活值。

- `void back_propagation(Layer&preLayer,nodetype learning_rate)`

  反向传播，依据后一层的delta计算这一层的delta并更新这一层的参数。

# class IFunction

## 成员函数

- `public virtual node_type activation(node_type) = 0`

  激活函数

- `public virtual node_type d_activation(node_type) = 0`

  激活函数的导数

# class LayerConstructionInfo

这一个类用于在Network进行构造的时候储存层的信息以用于构造层。储存的信息包括层的大小，激活函数，连接方式等等。

## 成员变量

- `public int size`

  这个层的节点数量

- `public IFunction * activation`

  这个曾使用的激活函数

# class Network

## 成员变量

- `private Layer * layers`

  这个神经网络的层

- `private size_t layer_size`

  神经网络的层数

## 成员函数

- `public Network(std::initialize_list<LayerConstructionInfo>)`

  构造函数，依据输入的层进行构造

- `~Network()` 析构函数

- `public void fit(double _lr, int epch, int btch_sz, std::string data_path, std::string label_path, std::string verify_data_path = "", std::string verify_label_path = "")`

  进行神经网络的训练

- `public const double[] evaluate(node_type data[])`

  读取`data`进行计算

- `public static LayerConstructionInfo * Layer(int size, IFunction activation)`

  返回一个结构体，其中存储了这个层的大小，激活函数。然后再通过调用Layer构造函数的方式构造Layer

> 还有其他函数可以在写代码的过程中再加上去。

